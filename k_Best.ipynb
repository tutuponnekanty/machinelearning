{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KTDCuwlKN8_m"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkNHkdUOWulS3YKo76HZIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tutuponnekanty/machinelearning/blob/main/k_Best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importing Required Libraries and Modules**"
      ],
      "metadata": {
        "id": "YUel9K3tKy-V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCqYGRms5k9J"
      },
      "outputs": [],
      "source": [
        "#importing required ML - Python Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rose-Pine-Dawn Matplotlib Module for Visual enhancement and 3D-graphical compatability with seaborn\n",
        "!wget https://raw.githubusercontent.com/h4pZ/rose-pine-matplotlib/main/themes/rose-pine-dawn.mplstyle -qP /tmp\n",
        "plt.style.use(\"/tmp/rose-pine-dawn.mplstyle\")"
      ],
      "metadata": {
        "id": "o1DOZUtK5xt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ignoring the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "24XZd_zl55_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading the datset and loading it into the VM\n",
        "!wget -q https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "!unzip -qq UCI\\ HAR\\ Dataset.zip"
      ],
      "metadata": {
        "id": "B-wgP_Ii5_5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading files into the colab\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "zIOj01cS6J5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the dataset\n",
        "df_samp = pd.read_csv(\"/content/UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt\", sep=\"\\s+\", header=None)\n",
        "df_samp.head()"
      ],
      "metadata": {
        "id": "ieXIqu57-S_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_samp_test = pd.read_csv(\"/content/UCI HAR Dataset/test/Inertial Signals/body_acc_x_test.txt\", sep=\"\\s+\", header=None)\n",
        "\n",
        "df_samp_test.head()"
      ],
      "metadata": {
        "id": "CjrvB4sT-0PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Accumilating the Dataset into one Array**"
      ],
      "metadata": {
        "id": "Y3eM7T66NzsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "f = open(\"/content/UCI HAR Dataset/README.txt\", \"r\", encoding=\"latin-1\")\n",
        "print(f.read())\n",
        "f.close()"
      ],
      "metadata": {
        "id": "p6oMmQjR-437"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(filepath):\n",
        "    df = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
        "    return df.values"
      ],
      "metadata": {
        "id": "ycXRjEO3MUq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_group(files, prefix=''):\n",
        "    loaded = list()\n",
        "    for f in files:\n",
        "        data = load_file(prefix + f)\n",
        "        loaded.append(data)\n",
        "    loaded = np.dstack(loaded)\n",
        "    return loaded"
      ],
      "metadata": {
        "id": "xivUlkKLM-P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset_group(group, prefix='/content/UCI HAR Dataset/'):\n",
        "    filepath = prefix + group + '/Inertial Signals/'\n",
        "    files = list()\n",
        "    files += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "    files += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "    files += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "    X = load_group(files, filepath)\n",
        "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "UN-0gW7FNAzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(prefix='/content/UCI HAR Dataset/'):\n",
        "    X_train, y_train = load_dataset_group('train', prefix)\n",
        "    X_test, y_test = load_dataset_group('test', prefix)\n",
        "    print(f\"\"\"Dataset loaded.\n",
        "Training Set:\n",
        "X_train {X_train.shape} y_train {y_train.shape}\n",
        "Test Set:\n",
        "X_test {X_test.shape} y_test {y_test.shape}\"\"\")\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "Fc5ZJWTyNG0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test = load_dataset()"
      ],
      "metadata": {
        "id": "CtR3YWBhNMn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activity = {\n",
        "        1: 'Walking',\n",
        "        2: 'Walking Upstairs',\n",
        "        3: 'Walking Downstairs',\n",
        "        4: 'Sitting',\n",
        "        5: 'Standing',\n",
        "        6: 'Laying'}\n",
        "def activities(obs):\n",
        "    return activity[int(y_train[obs])]"
      ],
      "metadata": {
        "id": "Ja77cb9-NWam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features(feature):\n",
        "    f={\"Body acceleration\": 0, \"Gyro\": 1, \"Total acceleration\": 2}\n",
        "    return f[feature]"
      ],
      "metadata": {
        "id": "RL5qvqzcNrCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample=[777, 666, 818, 0,6666,66]\n",
        "[activity[int(y_train[i])] for i in sample]"
      ],
      "metadata": {
        "id": "dD7bJ0YwNtPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_67hsqXbNwuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. EDA**"
      ],
      "metadata": {
        "id": "KTDCuwlKN8_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_values(y_values, T, N, f_s, sample_rate):\n",
        "    y_values = y_values\n",
        "    x_values = [sample_rate * kk for kk in range(0,len(y_values))]\n",
        "    return x_values, y_values"
      ],
      "metadata": {
        "id": "7hOwKEejN_HQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def signal_viz(obs):\n",
        "    N = 128  # number of timesteps\n",
        "    f_s = 50  # overlapped percentage\n",
        "    t_n = 2.56  # time\n",
        "    T = t_n / N\n",
        "    sample_rate = 1 / f_s\n",
        "\n",
        "    labels = ['x-component', 'y-component', 'z-component']\n",
        "    colors = ['#eb6f92', '#9ccfd8', '#f6c177']  # Soft Rose Pine palette (red, cyan, gold)\n",
        "    suptitle = \"Different signals for the activity: {}\"\n",
        "    xlabel = 'Time [sec]'\n",
        "    ylabel = 'Amplitude'\n",
        "    axtitles = ['Body acceleration', 'Gyro', 'Total acceleration']\n",
        "    activity_name = activities(obs)\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(24, 8))\n",
        "    fig.patch.set_facecolor('#faf4ed')  # Rose Pine Dawn background\n",
        "\n",
        "    for comp_no in range(0, 9):\n",
        "        col_no = comp_no // 3\n",
        "        plot_no = comp_no % 3\n",
        "        color = colors[plot_no]\n",
        "        label = labels[plot_no]\n",
        "        axtitle = axtitles[col_no]\n",
        "\n",
        "        ax = axes[col_no]\n",
        "        ax.set_title(axtitle, fontsize=16)\n",
        "        ax.set_xlabel(xlabel, fontsize=14)\n",
        "        ax.set_facecolor('#faf4ed')  # Light background for axes\n",
        "        ax.grid(True, color='#e0def4', linestyle='--', linewidth=0.5, alpha=0.7)\n",
        "\n",
        "        if col_no == 0:\n",
        "            ax.set_ylabel(ylabel, fontsize=14)\n",
        "\n",
        "        signal_component = X_train[obs][:, comp_no]\n",
        "        x_values, y_values = get_values(signal_component, T, N, f_s, sample_rate)\n",
        "        ax.plot(x_values, y_values, linestyle='-', color=color, label=label, linewidth=1.8)\n",
        "\n",
        "        if col_no == 2:\n",
        "            ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=12)\n",
        "\n",
        "    fig.suptitle(suptitle.format(activity_name), fontsize=20, weight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.88, hspace=0.4)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "B6kQ31frOBTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sample:\n",
        "    signal_viz(i)"
      ],
      "metadata": {
        "id": "CZ5LP7XXOGwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Apply Rose Pine Dawn styling\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=1.8)\n",
        "\n",
        "def signal_3dviz(obs, feature):\n",
        "    # Assuming `activities()` returns the activity name and `features()` gives the index\n",
        "    activity_name = activities(obs)\n",
        "    i = features(feature)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    ax = fig.add_subplot(111, projection=\"3d\")\n",
        "    fig.patch.set_facecolor('#faf4ed')  # Background to match style\n",
        "\n",
        "    # Extract 3D components\n",
        "    x = X_train[obs][:, i * 3 + 0]\n",
        "    y = X_train[obs][:, i * 3 + 1]\n",
        "    z = X_train[obs][:, i * 3 + 2]\n",
        "\n",
        "    # Use a soft color from Rose Pine palette\n",
        "    ax.plot(x, y, z, color=\"#eb6f92\", label=feature, linewidth=2.5)\n",
        "\n",
        "    # Labels and title\n",
        "    ax.set_title(activity_name, fontsize=20, weight='bold')\n",
        "    ax.set_xlabel(\"X\", fontsize=16)\n",
        "    ax.set_ylabel(\"Y\", fontsize=16)\n",
        "    ax.set_zlabel(\"Z\", fontsize=16)\n",
        "\n",
        "    # Make axes planes transparent\n",
        "    ax.xaxis.pane.fill = False\n",
        "    ax.yaxis.pane.fill = False\n",
        "    ax.zaxis.pane.fill = False\n",
        "\n",
        "    # Remove grid lines for a minimal look\n",
        "    ax.grid(False)\n",
        "\n",
        "    # Style ticks\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    ax.tick_params(axis='z', labelsize=12)\n",
        "\n",
        "    # Legend\n",
        "    ax.legend(fontsize=14)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IaoLkS1DOIh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sample:\n",
        "    signal_3dviz(i, \"Body acceleration\")"
      ],
      "metadata": {
        "id": "NjyHSkqGOSPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib as mpl\n",
        "\n",
        "# Apply Rose Pine Dawn styling\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=1.8)\n",
        "\n",
        "def signal_3dviz(obs, feature):\n",
        "    # Assuming `activities()` returns the activity name and `features()` gives the index\n",
        "    activity_name = activities(obs)\n",
        "    i = features(feature)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    ax = fig.add_subplot(111, projection=\"3d\")\n",
        "    fig.patch.set_facecolor('#faf4ed')  # Background to match style\n",
        "\n",
        "    # Extract 3D components\n",
        "    x = X_train[obs][:, i * 3 + 0]\n",
        "    y = X_train[obs][:, i * 3 + 1]\n",
        "    z = X_train[obs][:, i * 3 + 2]\n",
        "\n",
        "    # Use a soft color from Rose Pine palette\n",
        "    ax.plot(x, y, z, color=\"#eb6f92\", label=feature, linewidth=2.5)\n",
        "\n",
        "    # Labels and title\n",
        "    ax.set_title(activity_name, fontsize=20, weight='bold')\n",
        "    ax.set_xlabel(\"X\", fontsize=16)\n",
        "    ax.set_ylabel(\"Y\", fontsize=16)\n",
        "    ax.set_zlabel(\"Z\", fontsize=16)\n",
        "\n",
        "    # Make axes planes transparent\n",
        "    ax.xaxis.pane.fill = False\n",
        "    ax.yaxis.pane.fill = False\n",
        "    ax.zaxis.pane.fill = False\n",
        "\n",
        "    # Remove grid lines for a minimal look\n",
        "    ax.grid(False)\n",
        "\n",
        "    # Style ticks\n",
        "    ax.tick_params(axis='x', labelsize=12)\n",
        "    ax.tick_params(axis='y', labelsize=12)\n",
        "    ax.tick_params(axis='z', labelsize=12)\n",
        "\n",
        "    # Legend\n",
        "    ax.legend(fontsize=14)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "YHderD9flL0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sample:\n",
        "    signal_3dviz(i, \"Gyro\")"
      ],
      "metadata": {
        "id": "cy-qh7dolQ0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Apply Rose Pine Dawn style globally\n",
        "sns.set_theme(style=\"white\", font_scale=1.8)\n",
        "\n",
        "def distance_viz(obs, feature):\n",
        "    graph_name = \"graph/distance {} {}.png\"\n",
        "    activity_name = activities(obs)\n",
        "\n",
        "    i = features(feature)\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    fig.patch.set_facecolor('#faf4ed')  # Rose Pine Dawn background\n",
        "\n",
        "    # Extract components\n",
        "    x = X_train[obs][:, i * 3 + 0]\n",
        "    y = X_train[obs][:, i * 3 + 1]\n",
        "    z = X_train[obs][:, i * 3 + 2]\n",
        "\n",
        "    # Calculate Euclidean distance\n",
        "    distance = (x**2 + y**2 + z**2)**0.5\n",
        "\n",
        "    # Plot with soft, warm Rose Pine color\n",
        "    plt.plot(distance, label=feature, color=\"#eb6f92\", linewidth=2.2)\n",
        "\n",
        "    # Labels and title\n",
        "    plt.title(activity_name, fontsize=20, weight='bold')\n",
        "    plt.xlabel(\"Timesteps\", fontsize=16)\n",
        "    plt.ylabel(\"Distance\", fontsize=16)\n",
        "\n",
        "    # Legend\n",
        "    plt.legend(fontsize=14)\n",
        "\n",
        "    # Ticks styling\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "\n",
        "    # Optional: Remove top and right spines for minimalism\n",
        "    sns.despine()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4VtTO945QYIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sample:\n",
        "    distance_viz(i, \"Body acceleration\")"
      ],
      "metadata": {
        "id": "2wQtHSm5Qbtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Apply Rose Pine Dawn style\n",
        "sns.set_theme(style=\"whitegrid\", font_scale=2.5)\n",
        "\n",
        "def y_graph():\n",
        "    # Combine labels and map to activity names\n",
        "    y = pd.DataFrame(np.concatenate((y_train, y_test)), columns=[\"Activity\"])\n",
        "    y[\"Activity\"] = y[\"Activity\"].map(activity)\n",
        "\n",
        "    # Create the figure\n",
        "    fig, ax = plt.subplots(figsize=(36, 14))\n",
        "    fig.patch.set_facecolor('#faf4ed')  # Rose Pine background\n",
        "\n",
        "    # Plot with a soft color palette\n",
        "    sns.countplot(data=y, y=\"Activity\", ax=ax, palette=[\"#eb6f92\", \"#9ccfd8\", \"#f6c177\", \"#31748f\", \"#c4a7e7\", \"#ea9a97\", \"#f6c177\"])\n",
        "\n",
        "    # Titles and labels\n",
        "    ax.set_title(\"Observations by Activity\", fontsize=28, weight='bold')\n",
        "    ax.set_xlabel(\"Count\", fontsize=22)\n",
        "    ax.set_ylabel(\"Activity\", fontsize=22)\n",
        "\n",
        "    # Customize tick sizes\n",
        "    ax.tick_params(axis='x', labelsize=18)\n",
        "    ax.tick_params(axis='y', labelsize=18)\n",
        "\n",
        "    # Remove spines for minimal look\n",
        "    sns.despine(left=True, bottom=True)\n",
        "\n",
        "    # Tight layout\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "R6klChh2QdMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_graph()"
      ],
      "metadata": {
        "id": "hayagWQiQmSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZAvv6ARmSEL-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1X4a9d_iu2Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Filter Based Approach (main) - Fischer's Score with Selective Feature Selection**"
      ],
      "metadata": {
        "id": "9CHdLDmsu3Ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mYAgn7Cwu9qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Activity'].value_counts()"
      ],
      "metadata": {
        "id": "hP_QSecTwM-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "sJY-2LFqwPLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T"
      ],
      "metadata": {
        "id": "RKGvIF8GifqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "id": "BM_a0-zVij_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Activity', axis=1)\n",
        "y = df['Activity']\n",
        "\n",
        "# Encode target labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZV2JmxcqwS7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "G6ugBDBNwUEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#log-reg\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "f2FADjriwYwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy score for Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Test accuracy:\", accuracy_rf)\n"
      ],
      "metadata": {
        "id": "xWrzYi07HZ1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_duplicate_columns(df):\n",
        "\n",
        "    duplicate_columns = {}\n",
        "    seen_columns = {}\n",
        "\n",
        "    for column in df.columns:\n",
        "        current_column = df[column]\n",
        "\n",
        "        # Convert column data to bytes\n",
        "        try:\n",
        "            current_column_hash = current_column.values.tobytes()\n",
        "        except AttributeError:\n",
        "            current_column_hash = current_column.to_string().encode()\n",
        "\n",
        "        if current_column_hash in seen_columns:\n",
        "            if seen_columns[current_column_hash] in duplicate_columns:\n",
        "                duplicate_columns[seen_columns[current_column_hash]].append(column)\n",
        "            else:\n",
        "                duplicate_columns[seen_columns[current_column_hash]] = [column]\n",
        "        else:\n",
        "            seen_columns[current_column_hash] = column\n",
        "\n",
        "    return duplicate_columns"
      ],
      "metadata": {
        "id": "BGPtHQ2VwaxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_columns = get_duplicate_columns(X_train)"
      ],
      "metadata": {
        "id": "hBex-Zrmwlh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_columns"
      ],
      "metadata": {
        "id": "oup-LPNjwouw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[['tBodyAccMag-mean()','tBodyAccMag-sma()','tGravityAccMag-mean()','tGravityAccMag-sma()']]"
      ],
      "metadata": {
        "id": "vlJxWBKKwpua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for one_list in duplicate_columns.values():\n",
        "    X_train.drop(columns=one_list,inplace=True)\n",
        "    X_test.drop(columns=one_list,inplace=True)"
      ],
      "metadata": {
        "id": "WNi76VFcwu7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "HOmVJCH4wy0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "sel = VarianceThreshold(threshold=0.05)\n",
        "\n"
      ],
      "metadata": {
        "id": "b7BWuPKsw1WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sel.fit(X_train)"
      ],
      "metadata": {
        "id": "2-pj8zGuw3wO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(sel.get_support())"
      ],
      "metadata": {
        "id": "2ox81I7Tw5uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = X_train.columns[sel.get_support()]"
      ],
      "metadata": {
        "id": "x1tVYYyKw72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns"
      ],
      "metadata": {
        "id": "GRofIO7Lw-Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = sel.transform(X_train)\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=columns)\n",
        "X_test = pd.DataFrame(X_test, columns=columns)"
      ],
      "metadata": {
        "id": "Eg5YXRMvxAAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "9FSNU-9BxCRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use Rose Pine Dawn style\n",
        "sns.set_theme(style=\"white\", font_scale=0.5)  # Smaller font for high-dimension data\n",
        "\n",
        "def big_corr_heatmap():\n",
        "    corr_matrix = X_train.corr()\n",
        "\n",
        "    # Set up a big figure so the plot can be zoomed\n",
        "    fig, ax = plt.subplots(figsize=(50, 40))  # Adjust size if needed\n",
        "    fig.patch.set_facecolor('#faf4ed')\n",
        "\n",
        "    # Draw the heatmap\n",
        "    sns.heatmap(corr_matrix,\n",
        "                cmap=\"mako\",  # a soft seaborn-compatible colormap\n",
        "                linewidths=0.05,\n",
        "                linecolor='#e0def4',\n",
        "                square=True,\n",
        "                cbar_kws={'shrink': 0.4},\n",
        "                xticklabels=False,\n",
        "                yticklabels=False,\n",
        "                ax=ax)\n",
        "\n",
        "    # Optional: Title\n",
        "    ax.set_title(\"Correlation Heatmap of Features\", fontsize=20, weight='bold', pad=20)\n",
        "\n",
        "    # Tighter layout for clarity\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "76gIUpr4xEYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def big_corr_heatmap():\n",
        "    corr_matrix = X_train.corr()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(50, 40))\n",
        "    fig.patch.set_facecolor('#faf4ed')\n",
        "\n",
        "    sns.heatmap(\n",
        "        corr_matrix,\n",
        "        cmap=\"mako\",\n",
        "        linewidths=0.05,\n",
        "        linecolor='#e0def4',\n",
        "        square=True,\n",
        "        cbar_kws={'shrink': 0.4},\n",
        "        xticklabels=False,\n",
        "        yticklabels=False,\n",
        "        ax=ax\n",
        "    )\n",
        "\n",
        "    ax.set_title(\"Correlation Heatmap of Features\", fontsize=20, weight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show it\n",
        "big_corr_heatmap()\n"
      ],
      "metadata": {
        "id": "kSAdebsOnoW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = X_train.corr()"
      ],
      "metadata": {
        "id": "n494zsoCnYDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = corr_matrix.columns\n",
        "\n",
        "columns_to_drop = []\n",
        "\n",
        "for i in range(len(columns)):\n",
        "    for j in range(i + 1, len(columns)):\n",
        "        if corr_matrix.loc[columns[i], columns[j]] > 0.95:\n",
        "            columns_to_drop.append(columns[j])\n",
        "\n",
        "print(len(columns_to_drop))"
      ],
      "metadata": {
        "id": "GcCjxTyPx19d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop=set(columns_to_drop)\n",
        "len(columns_to_drop)"
      ],
      "metadata": {
        "id": "Uq5F2qnJx4YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "TMglx3Nsx5PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train.drop(columns = columns_to_drop, axis = 1, inplace=True)\n",
        "X_test.drop(columns = columns_to_drop, axis = 1, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "VjPIQeuCx8-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "NK-a_cSMx96F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA"
      ],
      "metadata": {
        "id": "uBdz-_mjx_8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "\n",
        "sel = SelectKBest(f_classif, k=153).fit(X_train, y_train)\n",
        "\n",
        "X_train.columns[sel.get_support()]\n",
        "\n"
      ],
      "metadata": {
        "id": "Wy_0Yo4JDmNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = X_train.columns[sel.get_support()]"
      ],
      "metadata": {
        "id": "7wCuXw6ayEql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X_train = sel.transform(X_train)\n",
        "X_test = sel.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=columns)\n",
        "X_test = pd.DataFrame(X_test, columns=columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "D8L4CsrKyHJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "rc5uu3QyyJCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "1w6O4bHgy-eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(max_iter=1000)  # Increase max_iter if it doesn't converge\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "hsfWcuHJzDHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_classifier = SVC(kernel='linear')\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy (SVM):\", accuracy)\n"
      ],
      "metadata": {
        "id": "Aji-Wplpz8Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Random Forest\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy (Random Forest):\", accuracy)\n"
      ],
      "metadata": {
        "id": "gvoblpYu0HJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Decision Tree\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test accuracy (Decision Tree):\", accuracy)\n"
      ],
      "metadata": {
        "id": "MDPcYg810R9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lazypredict"
      ],
      "metadata": {
        "id": "9smxV8qF00rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier()\n",
        "models = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models[0])"
      ],
      "metadata": {
        "id": "MJY5VmNb01nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Other Filter Based Methods (not recommended)**"
      ],
      "metadata": {
        "id": "7ESCK4qt5hji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "10fHf4g15nyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "2t4Z1axZ57b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('Activity', axis=1)\n",
        "y = df['Activity']\n",
        "\n",
        "# Encode target labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hG4hs9ic6HSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_duplicate_columns(df):\n",
        "\n",
        "    duplicate_columns = {}\n",
        "    seen_columns = {}\n",
        "\n",
        "    for column in df.columns:\n",
        "        current_column = df[column]\n",
        "\n",
        "        # Convert column data to bytes\n",
        "        try:\n",
        "            current_column_hash = current_column.values.tobytes()\n",
        "        except AttributeError:\n",
        "            current_column_hash = current_column.to_string().encode()\n",
        "\n",
        "        if current_column_hash in seen_columns:\n",
        "            if seen_columns[current_column_hash] in duplicate_columns:\n",
        "                duplicate_columns[seen_columns[current_column_hash]].append(column)\n",
        "            else:\n",
        "                duplicate_columns[seen_columns[current_column_hash]] = [column]\n",
        "        else:\n",
        "            seen_columns[current_column_hash] = column\n",
        "\n",
        "    return duplicate_columns"
      ],
      "metadata": {
        "id": "69ZnctZ66WiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_columns = get_duplicate_columns(X_train)"
      ],
      "metadata": {
        "id": "poaw0Ie16el4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_columns"
      ],
      "metadata": {
        "id": "MzryNozy6hUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[['tBodyAccMag-mean()','tBodyAccMag-sma()','tGravityAccMag-mean()','tGravityAccMag-sma()']]"
      ],
      "metadata": {
        "id": "ZwBCYIuL6jmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for one_list in duplicate_columns.values():\n",
        "    X_train.drop(columns=one_list,inplace=True)\n",
        "    X_test.drop(columns=one_list,inplace=True)"
      ],
      "metadata": {
        "id": "E2CII_q36mZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "G1PZDyDA6oTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHI2"
      ],
      "metadata": {
        "id": "2m4fkmyy6uQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "Ae4NQrCB7NDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "-_dAoW327Nfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('feature_selection', SelectKBest(score_func=chi2)),\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])\n"
      ],
      "metadata": {
        "id": "RUWYzSpT7S-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'feature_selection__k': [10, 20, 30, 50, 75, 100, 110, 120]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "zxgRC9Y97Vbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with top chi2-selected features: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "_QFEDSeJ7YTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lazypredict\n",
        "from lazypredict.Supervised import LazyClassifier\n",
        "\n",
        "clf = LazyClassifier()\n",
        "models = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models[0])"
      ],
      "metadata": {
        "id": "pLtZW4gQ8rzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EhxJBdDnp0yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mutual Info"
      ],
      "metadata": {
        "id": "ZWL1eT2v8eXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "cRjpyfWt99qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "9t1yNUFk-OvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('feature_selection', SelectKBest(score_func=mutual_info_classif)),\n",
        "    ('clf', RandomForestClassifier(random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "eQSZTuHG-R7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'feature_selection__k': [10, 20, 30, 50, 75, 'all']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "K4zjI8D4-WUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best k value (Mutual Info):\", grid_search.best_params_['feature_selection__k'])\n",
        "print(f\"Accuracy with best k (MI): {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "QD7w4zQj-XQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mi_scores = mutual_info_classif(X_train_scaled, y_train)\n",
        "sorted_indices = np.argsort(mi_scores)[::-1]\n",
        "print(\"Top 10 MI feature indices:\", sorted_indices[:10])\n",
        "print(\"Top 10 MI scores:\", mi_scores[sorted_indices[:10]])\n"
      ],
      "metadata": {
        "id": "k3MmvZfn-kc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eiFquT9P-4Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.Iterative feature selection - CHI SQUARE**"
      ],
      "metadata": {
        "id": "clihBudpo2V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "QlZQosDVo43Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train_scaled.shape[1]\n",
        "\n",
        "k_values = []\n",
        "accuracies = []"
      ],
      "metadata": {
        "id": "HKhT5J4Bo6sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in tqdm(range(1, num_features + 1)):\n",
        "    selector = SelectKBest(score_func=chi2, k=k)\n",
        "    X_train_k = selector.fit_transform(X_train_scaled, y_train)\n",
        "    X_test_k = selector.transform(X_test_scaled)\n",
        "\n",
        "    clf = RandomForestClassifier(random_state=42)\n",
        "    clf.fit(X_train_k, y_train)\n",
        "    y_pred = clf.predict(X_test_k)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    k_values.append(k)\n",
        "    accuracies.append(acc)"
      ],
      "metadata": {
        "id": "LEIQX_0Bo_1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: k_values = np.array(k_values)\n",
        "# accuracies = np.array(accuracies)\n",
        "# display them and save them as a csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "k_values = np.array(k_values)\n",
        "accuracies = np.array(accuracies)\n",
        "\n",
        "# Display k_values and accuracies\n",
        "print(\"k_values:\", k_values)\n",
        "print(\"accuracies:\", accuracies)\n",
        "\n",
        "# Create a DataFrame\n",
        "df_results = pd.DataFrame({'k_values': k_values, 'accuracies': accuracies})\n",
        "\n",
        "# Save to CSV\n",
        "df_results.to_csv('k_accuracy_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "WmrMf9NzGr9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_elbow_curve(k_values, accuracies):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(\n",
        "        k_values,\n",
        "        accuracies,\n",
        "        marker='o',\n",
        "        linestyle='-',\n",
        "        color='#eb6f92',\n",
        "        linewidth=2.5,\n",
        "        markersize=8,\n",
        "        markerfacecolor='#f6c177',\n",
        "        markeredgecolor='#31748f'\n",
        "    )\n",
        "\n",
        "    plt.title('Elbow Curve: Accuracy vs. Number of Features (Chi)', fontsize=18, weight='bold')\n",
        "    plt.xlabel('Number of Selected Features (k)', fontsize=14)\n",
        "    plt.ylabel('Accuracy', fontsize=14)\n",
        "\n",
        "    plt.grid(True, color='#c4a7e7', linestyle='--', linewidth=0.5)\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4j8uKlDIpCRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_elbow_curve(k_values, accuracies)"
      ],
      "metadata": {
        "id": "-fDXhlMSpVEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 30 k-values\n",
        "acc_array = np.array(accuracies)\n",
        "k_array = np.array(k_values)\n",
        "top_indices = acc_array.argsort()[::-1][:30]\n",
        "\n",
        "top_k_acc = [(k_array[i], acc_array[i]) for i in top_indices]\n",
        "print(\"Top 10 k-values with corresponding accuracies (Chi):\")\n",
        "for k, acc in top_k_acc:\n",
        "    print(f\"k = {k}, Accuracy = {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "GUvhYPCHpG-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, the best accuracy we are getting is a t k = 180"
      ],
      "metadata": {
        "id": "2lcXvPyaCDk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# Fit Chi2 selector\n",
        "selector_180 = SelectKBest(score_func=chi2, k=180)\n",
        "X_train_180 = selector_180.fit_transform(X_train_scaled, y_train)\n",
        "X_test_180 = selector_180.transform(X_test_scaled)\n",
        "\n",
        "# Get selected feature indices\n",
        "selected_indices_180 = selector_180.get_support(indices=True)\n",
        "print(\"Selected feature indices (k=180):\", selected_indices_180)\n"
      ],
      "metadata": {
        "id": "ioXkKsI2CHLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if isinstance(X_train, pd.DataFrame):\n",
        "    selected_features_180 = X_train.columns[selected_indices_180]\n",
        "    print(\"Selected feature names (k=180):\")\n",
        "    for i, name in enumerate(selected_features_180, 1):\n",
        "        print(f\"{i:3}: {name}\")\n"
      ],
      "metadata": {
        "id": "eF275IN1C1Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "# Step 1: Select top 180 features\n",
        "selector_180 = SelectKBest(score_func=chi2, k=180)\n",
        "X_train_180 = selector_180.fit_transform(X_train_scaled, y_train)\n",
        "X_test_180 = selector_180.transform(X_test_scaled)\n",
        "\n",
        "# Step 2: Train model\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train_180, y_train)\n",
        "y_pred = clf.predict(X_test_180)\n",
        "\n",
        "# Step 3: Compute metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Display metrics\n",
        "print(\"=== Performance with Top 180 Chi Features ===\")\n",
        "print(f\"Accuracy       : {acc:.4f}\")\n",
        "print(f\"Precision      : {prec:.4f}\")\n",
        "print(f\"Recall         : {rec:.4f}\")\n",
        "print(f\"F1-Score       : {f1:.4f}\")\n",
        "print(\"\\n=== Confusion Matrix ===\")\n",
        "print(cm)\n",
        "\n",
        "# Optional: Detailed class-wise report\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred, zero_division=0))\n"
      ],
      "metadata": {
        "id": "SOs3TuZgC_DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4TCVSYxF8SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Conclusion**"
      ],
      "metadata": {
        "id": "138mqinhD_2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Conclusion\n",
        "\n",
        "In this notebook, **filter-based feature selection methods** were used to improve the model's performance by reducing dimensionality and selecting the most informative features.\n",
        "\n",
        "From the initial **Exploratory Data Analysis (EDA)**, it was clear that this is a **discrete vs categorical classification** problem. Based on this observation, I began the process with **Fishers Score-based feature selection**, which is well-suited for such scenarios.\n",
        "\n",
        "---\n",
        "\n",
        "###  Summary of Dataset & Base Model\n",
        "\n",
        "- **Total Features**: 561  \n",
        "- **Base Model**: Logistic Regression (used because it is:\n",
        "  - Efficient for high-dimensional data\n",
        "  - Easy to interpret\n",
        "  - Provides strong baseline performance)\n",
        "- **Accuracy with all 561 features**: **98.7%**\n",
        "\n",
        "---\n",
        "\n",
        "###  Fisher's Score-Based Feature Selection + Similar Feature Elimination\n",
        "\n",
        "1. **Data Preprocessing Steps**:\n",
        "   - Removed duplicate and constant features\n",
        "   - Eliminated highly similar features using cosine similarity-based filtering\n",
        "   - Performed feature selection using Fisher Score\n",
        "\n",
        "2. **Final Feature Count**: 153  \n",
        "3. **Accuracy (Logistic Regression)**: **97.0%**  \n",
        "4. **Highest Accuracy (using other classifiers)**: **99.0%** *(not recommended due to potential overfitting or model complexity)*\n",
        "\n",
        "---\n",
        "\n",
        "###  Iterative Chi Feature Selection\n",
        "\n",
        "- An **empty dictionary** was initialized to store `(k, accuracy)` for each iteration.\n",
        "- Loop ran from `k = 1` to `k = 561` (i.e., `'all'`).\n",
        "- For each `k`, the Chi filter was applied and accuracy recorded.\n",
        "- After collecting all results, the top 30 entries were analyzed.\n",
        "\n",
        "####  Best `k` (Lowest `k` with Top Accuracy): **180**\n",
        "\n",
        "- **Model Used**: Logistic Regression  \n",
        "- **Accuracy with 180 Chi Features**: **98.3%**  \n",
        "- This is slightly below the base model but still very competitive, considering the dimensionality reduction.\n",
        "\n",
        "---\n",
        "\n",
        "###  Time Comparison of Methods\n",
        "\n",
        "| Method                             | Time Taken     |\n",
        "|------------------------------------|----------------|\n",
        "| Fishers Score + Feature Elimination | ~5 minutes     |\n",
        "| Iterative Chi (1 to all)           | ~1 hour 10 mins |\n",
        "\n",
        "---\n",
        "\n",
        "###  Final Thoughts\n",
        "\n",
        "- **Fisher's Score** with feature elimination is **faster** and gives a **decent performance drop (1.7%)**.\n",
        "- **Chi** is **computationally heavier**, but selecting an optimal `k` gave us a **very close accuracy** to the full feature set.\n",
        "- Both methods helped reduce overfitting risks, simplified the model, and made it easier to interpret.\n"
      ],
      "metadata": {
        "id": "v7gmE2pvFxvc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ePGKP2dEDea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}